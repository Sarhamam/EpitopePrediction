{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Epitope_project_template.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdrY6FXSJf2v"
   },
   "source": [
    "Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "infG8tvNJj8d"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from google.colab import drive\n",
    "\n",
    "# Check if GPU available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Detected CUDA on device #{torch.cuda.current_device()}: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"NO GPU FOUND !!!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0FRFJT1spbmq"
   },
   "source": [
    "# Arrange required files:\n",
    "\n",
    "# Mount google drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "# Clone repository\n",
    "REPO = 'https://github.com/Sarhamam/EpitopePrediction.git'\n",
    "EPI_PATH = '/content/EpitopePrediction'\n",
    "!git clone $REPO $EPI_PATH\n",
    "\n",
    "# Install packages\n",
    "!pip install -r $EPI_PATH/requirements.txt "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12wvazn0PFsF"
   },
   "source": [
    "Define NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o0VnvdSGPP3l"
   },
   "source": [
    "# Parameters\n",
    "params = {\n",
    "  'input_file': \"<PATH_TO_INPUT_FILE>\",\n",
    "  'output_file':\"<PATH_TO_OUTPUT_FILE>\",\n",
    "  'mode': 'predict',\n",
    "  'weights': \"../resources/weights.pytw\",\n",
    "  'rnn_type': 'GRU',\n",
    "  'bidirectional': True,\n",
    "  'batch_size': 15,\n",
    "  'concat_after': False,\n",
    "  'window_size': -1,\n",
    "  'window_overlap': 0,\n",
    "  'loss_at_end': False,\n",
    "  'epochs': 15,\n",
    "  'max_batches': 1,\n",
    "  'max_length': 10000,\n",
    "  'hidden_dim': 256,\n",
    "  'n_layers': 2,\n",
    "  'lr': 3.3e-5,\n",
    "  'numeric_features': True,\n",
    "  'accuracy_report': \"/gdrive/MyDrive/report.csv\",\n",
    "  'weighted_loss': True,\n",
    "  'deterministic': False\n",
    "}\n",
    "\n",
    "def execute(params):\n",
    "  # construct flags\n",
    "  flags = \"\"\n",
    "  main = \"main.py\"\n",
    "  for k, v in params.items():\n",
    "    if k in ['input_file','output_file','mode']:\n",
    "      flags = ' '.join([flags,str(v)])\n",
    "    else:\n",
    "      flags = ' '.join([flags,'--'+k,str(v)])\n",
    "  cmd = ' '.join([main,flags.lstrip()])\n",
    "  print(cmd)\n",
    "  %cd $EPI_PATH/src/\n",
    "  !ls ../resources/\n",
    "  !python $cmd\n",
    "  \n",
    "def study_summary(params):\n",
    "  results = pd.read_csv(params['accuracy_report'],delim_whitespace=True)\n",
    "  epoch_num = results['Epoch #']\n",
    "  train_loss = results['Train loss']\n",
    "  train_recall = results['Train recall']\n",
    "  train_precision = results['Train precision']\n",
    "  return epoch_num,train_loss,train_recall,train_precision\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2cTGrII4T7pZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Example train run.\n",
    "REPORT_FILE=\"/gdrive/MyDrive/report_0.csv\"\n",
    "!touch $REPORT_FILE\n",
    "params_0 = params.copy()\n",
    "params_0['mode'] = 'train'\n",
    "params_0['accuracy_report'] = REPORT_FILE\n",
    "params_0['input_file'] = \"../resources/example.fasta\"\n",
    "params_0['output_file'] = \"/gdrive/MyDrive/weights.pytw\"\n",
    "params_0['epochs'] = 1\n",
    "params_0['bidirectional'] = False\n",
    "params_0['numeric_features']= False\n",
    "print(\"params 0\")\n",
    "print(params_0)\n",
    "execute(params_0) # uncomment to run\n",
    "param0 = study_summary(params_0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sZIezngLRJRv"
   },
   "source": [
    "# Example predict run.\n",
    "params_0 = params.copy()\n",
    "params_0['mode'] = 'predict'\n",
    "params_0['output_file'] = \"/gdrive/MyDrive/report_0.out\"\n",
    "params_0['input_file'] = \"../resources/example.fasta\"\n",
    "print(\"params 0\")\n",
    "print(params_0)\n",
    "execute(params_0) # uncomment to run\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzrNf-Z6TCoG"
   },
   "source": [
    ""
   ]
  }
 ]
}